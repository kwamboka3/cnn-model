{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project - Understanding Document Clustering\n",
    "\n",
    "Clustering is one of the most important Unsupervised Machine Learning Techniques. These algorithms come in handy, especially in situations where labelled data is a luxury. Clustering techniques help us understand the underlying patterns in data (more so around them being similar) along with the ability to bootstrap certain supervised learning approaches as well.\n",
    "\n",
    "![](avengers.jpg)\n",
    "\n",
    "Clustering techniques have been studied in depth over the years and there are some very powerful clustering algorithms available. For this tutorial, we will be working with a movie dataset containing movie plot, cast, genres and related other information. We will be working with __K-Means__ and __Ward-Hierarchical-Clustering__ methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../Unit 10 - Project 8 - Movie Recommendations with Document Similarity/tmdb_5000_movies.csv.gz', \n",
    "                 compression='gzip')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df[['title', 'tagline', 'overview', 'genres', 'popularity']]\n",
    "df.tagline.fillna('', inplace=True)\n",
    "df['description'] = df['tagline'].map(str) + ' ' + df['overview']\n",
    "df.dropna(inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Turn: Cluster Similar Movies\n",
    "\n",
    "Here you will learn how to cluster text documents (in this case movies). We will use the following pipeline:\n",
    "- Text pre-processing\n",
    "- Feature Engineering\n",
    "- Clustering Using K-Means\n",
    "- Finding Optimal Value for K\n",
    "- Prepare Movie Clusters\n",
    "\n",
    "Clustering is an unsupervised approach to find groups of similar items in any given dataset. There are different clustering algorithms and __K-Means__ is a pretty simple yet affect one. Most movies span different emotions and can be categorized into multiple genres (same is the case with movies listed in our current dataset). Can clustering of movie descriptions help us understand these groupings?\n",
    "\n",
    "Similarity analysis (in the previous section) was a good starting point, but can we do better? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text pre-processing\n",
    "\n",
    "We will do some basic text pre-processing on our movie descriptions before we build our features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def normalize_document(doc):\n",
    "    # lower case and remove special characters\\whitespaces\n",
    "    doc = re.sub(r'[^a-zA-Z0-9\\s]', '', doc, re.I|re.A)\n",
    "    doc = doc.lower()\n",
    "    doc = doc.strip()\n",
    "    # tokenize document\n",
    "    tokens = nltk.word_tokenize(doc)\n",
    "    # filter stopwords out of document\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    # re-create document from filtered tokens\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "    return doc\n",
    "\n",
    "normalize_corpus = np.vectorize(normalize_document)\n",
    "\n",
    "norm_corpus = normalize_corpus(list(df['description']))\n",
    "len(norm_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract TF-IDF Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tf = TfidfVectorizer(ngram_range=(1, 2), min_df=2)\n",
    "tfidf_matrix = tf.fit_transform(norm_corpus)\n",
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Movies using K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2, max_iter=100,random_state=42).fit(____) #feature matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Movie Distribution Across Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Counter(kmeans.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying K\n",
    "\n",
    "Since most movies are a combination of emotions, stories, characters, scenary, etc, let us try and utilize K-means to see if the movies can be grouped into common themes capturing some of these underlying aspects.\n",
    "\n",
    "One challenge we face while working with K-Means is finding the right value of K. To do so, there are a few heuristics like _the silhouette_score_ and the _elbow_ method. \n",
    "\n",
    "### Sillhouette Score\n",
    "Silhouette Scoring helps in quantifying interpretation and validation of consistency within clusters of data. \n",
    "The silhouette score value quantifies how similar an item is to its own cluster (cohesion) compared to other clusters (separation). The silhouette score ranges from âˆ’1 to +1, where a high value indicates well placed item. A negative score indicates that there may be too many or too few clusters.\n",
    "\n",
    "### Elbow Method\n",
    "This method requires us to run k-means clustering on a given dataset for a range of values of k. Then for each value of k, we calculate sum of squared errors (SSE).\n",
    "\n",
    "The next step is to plot a line graph of the SSE aganist each value of k. The line graph looks like an arm, the _elbow_ on the arm is the value of optimal k (number of cluster). \n",
    "The goal is to choose a small value of k that still has a low SSE, and the elbow usually represents where we start to have diminishing returns by increasing k.\n",
    "\n",
    "The following snippet loops through different values of K, generates the silhouette scores as well the elbow plot to help us narrow down to the optimal value of K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def identify_k(feature_matrix, min_k=2,max_k=3):\n",
    "    sse = {}\n",
    "    for k in range(min_k,max_k):\n",
    "        kmeans = KMeans(n_clusters=k, max_iter=100,random_state=42).fit(_____)#feature matrix\n",
    "        sil_coeff = silhouette_score(tfidf_matrix, \n",
    "                                     _________,# cluster labels \n",
    "                                     metric='euclidean')\n",
    "        print(\"For K={}, Silhouette Coefficient = {}\".format(k, sil_coeff))\n",
    "        # Inertia: Sum of distances of samples to their closest cluster center\n",
    "        sse[k] = kmeans.inertia_ \n",
    "    plt.figure()\n",
    "    plt.plot(_______, ______) # x-axis=different values of k, y-axis=sse value for each k\n",
    "    plt.xlabel(\"K\")\n",
    "    plt.ylabel(\"SSE\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn\n",
    "Find the optimal value of K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# iterate from k=2 to k=10 and plot the elbow curve\n",
    "identify_k(___,___,____)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Cluster Labels\n",
    "For the current scenario, let us set __K=4__ and assign cluster labels to each of the movies in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(________).fit(____)\n",
    "df[\"cluster_label\"] = ______ # cluster labels\n",
    "df.cluster_label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Cluster Details\n",
    "\n",
    "Each cluster constitutes movies which have some underlying aspects which are common.\n",
    "We also understand that cluster centers are in a way representatives of the whole cluster. Let us utilize this understanding to extract top common features amongst clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cluster_details(clustering_obj, movie_data, \n",
    "                     feature_names, num_clusters,\n",
    "                     topn_features=10):\n",
    "\n",
    "    cluster_details = {}  \n",
    "    # get cluster centroids\n",
    "    ordered_centroids = clustering_obj.cluster_centers_.argsort()[:, ::-1]\n",
    "    \n",
    "    # get key features for each cluster\n",
    "    # get movies belonging to each cluster\n",
    "    for cluster_num in range(num_clusters):\n",
    "        cluster_details[cluster_num] = {}\n",
    "        cluster_details[cluster_num]['cluster_num'] = ____ # set cluster number\n",
    "        key_features = [_________]# extract key features from centroids\n",
    "        cluster_details[cluster_num]['key_features'] = key_features\n",
    "        \n",
    "        movies = ____________ # assign list of movies belonging to this cluster\n",
    "        cluster_details[cluster_num]['movies'] = movies\n",
    "    \n",
    "    return cluster_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_cluster_details(cluster_data,n_movies=5):\n",
    "    # print cluster details\n",
    "    for cluster_num, cluster_details in cluster_data.items():\n",
    "        print('Cluster {} details:'.format(cluster_num))\n",
    "        print('-'*20)\n",
    "        print('Key features:', ______)\n",
    "        print('Movies in this cluster:')\n",
    "        print(', '.join(_________))\n",
    "        print('='*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn\n",
    "\n",
    "Extract Cluster Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster_data =  get_cluster_details(clustering_obj=____, # clustering object\n",
    "                                     movie_data=df,\n",
    "                                     feature_names=_____, #hint:use the tfidf vectorizer to get list of features\n",
    "                                     num_clusters=4,\n",
    "                                     topn_features=5)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_cluster_details(______) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical Clustering\n",
    "So far, we were successfull in clustering movies using __K-Means__. But is there any further level of understanding we can extract from this dataset in an unsupervised manner?\n",
    "\n",
    "Hierarchical Clustering to the rescue. K-Means helped us understand similarities amongst movies, with hierarchical clustering we can aim at understanding abstract or higher level concepts which are common across groups of movies. There are primarily two ways in which hierarchical clustering can be performed:\n",
    "\n",
    "- Divisive : The algorithm begins with every element in one big generic cluster and then goes on dividing them into specific clusters in a recursive manner.\n",
    "- Agglomerative : In this case, the algorithm starts by placing every element into a cluster of its own and then goes on merging them into more general clusters in a recursive manner (till they all merge into one big cluster).\n",
    "\n",
    "For this tutorial, we will work with __Ward clustering algorithm__. Ward clustering is an agglomerative clustering method, i.e. at each stage, the pair of clusters with minimum _between-cluster distance_ (or wcss) are merged. \n",
    "\n",
    "To work with Ward Clustering Algorithm, we perform the following steps:\n",
    "-  Prepare a cosine distance matrix\n",
    "-  Calclate a linkage_matrix\n",
    "-  Plot the hierarchical structure as a dendrogram.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import ward, dendrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Linkage Matrix using Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ward_hierarchical_clustering(feature_matrix):\n",
    "    \n",
    "    cosine_distance = ________ # 1- cosine similarity of the features\n",
    "    linkage_matrix = ward(cosine_distance)\n",
    "    return linkage_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Hierarchical Structure as a Dendrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_hierarchical_clusters(linkage_matrix, movie_data, p=100, figure_size=(8,12)):\n",
    "    # set size\n",
    "    fig, ax = plt.subplots(figsize=figure_size) \n",
    "    movie_titles = _______ # extract movie titles as list\n",
    "    \n",
    "    # prepare dendrogram\n",
    "    R = dendrogram(linkage_matrix, \n",
    "                   orientation=\"left\", \n",
    "                   labels=movie_titles,\n",
    "                   truncate_mode='lastp',\n",
    "                   p=p, \n",
    "                   no_plot=True)\n",
    "    \n",
    "    temp = {R[\"leaves\"][ii]: movie_titles[ii] for ii in range(len(R[\"leaves\"]))}\n",
    "    def llf(xx):\n",
    "        return \"{}\".format(temp[xx])\n",
    "    \n",
    "    # plot dendrogram\n",
    "    ax = dendrogram(\n",
    "            ______, # linkage matrix\n",
    "            truncate_mode='lastp',\n",
    "            orientation=\"left\",\n",
    "            p=p,  \n",
    "            leaf_label_func=_____, # function to get leaf labels \n",
    "            leaf_font_size=10.,\n",
    "            )\n",
    "    plt.tick_params(axis= 'x',   \n",
    "                    which='both',  \n",
    "                    bottom='off',\n",
    "                    top='off',\n",
    "                    labelbottom='off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('movie_hierachical_clusters.png', dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn\n",
    "\n",
    "Use the above prepare utilities to perform hierarchical clustering and generate a dendrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "linkage_matrix = ward_hierarchical_clustering(______)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_hierarchical_clusters(___________)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
